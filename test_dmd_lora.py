#!/usr/bin/env python3
"""
æµ‹è¯•DMD LoRAåŠŸèƒ½çš„ç®€å•è„šæœ¬
"""

import torch
import argparse
import sys
import os

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥DMD
sys.path.insert(0, os.path.dirname(__file__))

def create_test_args():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„å‚æ•°é…ç½®"""
    args = argparse.Namespace()
    
    # åŸºç¡€DMDå‚æ•°
    args.model_name = "wan"
    args.generator_task = "causal_video"
    args.generator_grad = True
    args.real_score_grad = False
    args.fake_score_grad = True
    args.gradient_checkpointing = False  # æµ‹è¯•æ—¶å…³é—­ä»¥é¿å…å¤æ‚æ€§
    args.denoising_step_list = [0, 250, 500, 750, 999]
    args.num_train_timestep = 1000
    args.real_guidance_scale = 7.5
    args.denoising_loss_type = "flow"
    args.mixed_precision = True
    args.warp_denoising_step = False
    
    # å¯é€‰çš„checkpointè·¯å¾„ï¼ˆæµ‹è¯•æ—¶ä¸åŠ è½½ï¼‰
    args.generator_ckpt = None
    args.real_score_ckpt = None
    args.fake_score_ckpt = None
    
    return args

def test_dmd_without_lora():
    """æµ‹è¯•ä¸ä½¿ç”¨LoRAçš„DMDåˆå§‹åŒ–"""
    print("æµ‹è¯•1: DMDåˆå§‹åŒ–ï¼ˆä¸ä½¿ç”¨LoRAï¼‰")
    
    args = create_test_args()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        from dmd import DMD
        dmd = DMD(args, device)
        print("âœ“ DMDåˆå§‹åŒ–æˆåŠŸï¼ˆä¸ä½¿ç”¨LoRAï¼‰")
        return True
    except Exception as e:
        print(f"âœ— DMDåˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def test_dmd_with_lora_config():
    """æµ‹è¯•å¸¦æœ‰LoRAé…ç½®çš„DMDåˆå§‹åŒ–ï¼ˆä½†ä¸åŠ è½½å®é™…çš„checkpointæ–‡ä»¶ï¼‰"""
    print("\næµ‹è¯•2: DMDåˆå§‹åŒ–ï¼ˆå¸¦LoRAé…ç½®ï¼Œä½†ä¸åŠ è½½å®é™…æ–‡ä»¶ï¼‰")
    
    args = create_test_args()
    
    # æ·»åŠ LoRAé…ç½®ï¼Œä½†ä½¿ç”¨ä¸å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„
    # è¿™æ ·å¯ä»¥æµ‹è¯•é…ç½®è§£æé€»è¾‘ï¼Œè€Œä¸éœ€è¦å®é™…çš„checkpointæ–‡ä»¶
    args.real_score_lora_ckpt = None  # è®¾ä¸ºNoneä»¥è·³è¿‡å®é™…åŠ è½½
    args.real_score_lora_base_model = "model"
    args.real_score_lora_target_modules = "q,k,v,o"
    args.real_score_lora_rank = 16
    
    args.fake_score_lora_ckpt = None  # è®¾ä¸ºNoneä»¥è·³è¿‡å®é™…åŠ è½½
    args.fake_score_lora_base_model = "model"
    args.fake_score_lora_target_modules = "q,k,v,o"
    args.fake_score_lora_rank = 16
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        from dmd import DMD
        dmd = DMD(args, device)
        print("âœ“ DMDåˆå§‹åŒ–æˆåŠŸï¼ˆå¸¦LoRAé…ç½®ï¼‰")
        return True
    except Exception as e:
        print(f"âœ— DMDåˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def test_lora_helper_method():
    """æµ‹è¯•_add_lora_to_modelè¾…åŠ©æ–¹æ³•"""
    print("\næµ‹è¯•3: æµ‹è¯•_add_lora_to_modelæ–¹æ³•")
    
    try:
        from dmd import DMD
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹æ¥æµ‹è¯•LoRAæ³¨å…¥
        class SimpleModel(torch.nn.Module):
            def __init__(self):
                super().__init__()
                self.q = torch.nn.Linear(64, 64)
                self.k = torch.nn.Linear(64, 64)
                self.v = torch.nn.Linear(64, 64)
                self.o = torch.nn.Linear(64, 64)
        
        model = SimpleModel()
        
        # åˆ›å»ºDMDå®ä¾‹æ¥è®¿é—®_add_lora_to_modelæ–¹æ³•
        args = create_test_args()
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dmd = DMD(args, device)
        
        # æµ‹è¯•LoRAæ³¨å…¥
        model_with_lora = dmd._add_lora_to_model(
            model=model,
            target_modules=["q", "k", "v", "o"],
            lora_rank=8
        )
        
        print("âœ“ _add_lora_to_modelæ–¹æ³•å·¥ä½œæ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âœ— _add_lora_to_modelæ–¹æ³•æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_lora_parameter_parsing():
    """æµ‹è¯•LoRAå‚æ•°è§£æ"""
    print("\næµ‹è¯•4: LoRAå‚æ•°è§£æ")
    
    args = create_test_args()
    
    # è®¾ç½®ä¸€äº›LoRAå‚æ•°
    args.real_score_lora_target_modules = "q,k,v,o,ffn.0,ffn.2"
    args.real_score_lora_rank = 32
    
    try:
        # æµ‹è¯•å‚æ•°è§£æ
        target_modules = getattr(args, "real_score_lora_target_modules", "q,k,v,o,ffn.0,ffn.2")
        parsed_modules = target_modules.split(",")
        
        expected_modules = ["q", "k", "v", "o", "ffn.0", "ffn.2"]
        assert parsed_modules == expected_modules, f"æ¨¡å—è§£æé”™è¯¯: {parsed_modules} != {expected_modules}"
        
        rank = getattr(args, "real_score_lora_rank", 32)
        assert rank == 32, f"Rankè§£æé”™è¯¯: {rank} != 32"
        
        print("âœ“ LoRAå‚æ•°è§£ææ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"âœ— LoRAå‚æ•°è§£æå¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹DMD LoRAåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        test_dmd_without_lora,
        test_dmd_with_lora_config,
        test_lora_helper_method,
        test_lora_parameter_parsing
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
    
    print("\n" + "=" * 50)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
        return True
    else:
        print("âŒ æœ‰æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 